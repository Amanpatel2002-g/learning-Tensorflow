{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Regression with Neural Network in Tensorfllow \n",
    "\n",
    "There are many definations for a regression problem but in our case. we're going to simplify it. predicting a numerical variable based on some other combination of variables , even shorter.. pridicting a number\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow \n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating some data \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# create features\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0,  5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "#create labels\n",
    "y=np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "#visualize it\n",
    "plt.scatter(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y==X+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and Output shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a demo tensor for housing price prediction problem\n",
    "\n",
    "house_info = tf.constant(['bedroom', 'bathroom', 'garage'])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4.0, 6.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shpae = y[0].shape\n",
    "input_shape, output_shpae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn our Numpy arrays into tensors in float 32\n",
    "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shpae = y[0].shape\n",
    "input_shape, output_shpae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2114a68c310>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps in modelling with Tensorflow\n",
    "\n",
    "1. **Creating a model** - define the input and output layers, as well as hidden layers of a deep learning model\n",
    "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our model).\n",
    "3. **Fitting a model**-letting the model try to find patterns between X & y (features and labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 13.1004 - mae: 13.1004\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12.9679 - mae: 12.9679\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 12.8354 - mae: 12.8354\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 12.7029 - mae: 12.7029\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.5704 - mae: 12.5704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2114a8505e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1. Create a model using the sequential API\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "    # tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "#2. complile the model\n",
    "model.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(),metrics=[\"mae\"])\n",
    "\n",
    "#3. fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n"
     ]
    }
   ],
   "source": [
    "# Try and make a prediction with our model\n",
    "y_pred = model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15.966148]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred+11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Improving a model**\n",
    "\n",
    "We can improve our model, by altering the steps we took to create a model\n",
    "\n",
    "1. **Adding layers**\n",
    "2. **Increase the number of hidden units**\n",
    "3. **Change the activation function**\n",
    "4. **change the optimization function**\n",
    "5. **change the learning rate**\n",
    "6. **Fitting on more data**\n",
    "7. **Fitting for longer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 17.7116 - mae: 17.7116\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 17.4304 - mae: 17.4304\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 17.1491 - mae: 17.1491\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 16.8679 - mae: 16.8679\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 16.5866 - mae: 16.5866\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 16.3054 - mae: 16.3054\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 16.0241 - mae: 16.0241\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 15.7429 - mae: 15.7429\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 15.4616 - mae: 15.4616\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 15.1804 - mae: 15.1804\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 14.8991 - mae: 14.8991\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 14.7040 - mae: 14.7040\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 14.5715 - mae: 14.5715\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 14.4390 - mae: 14.4390\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 14.3065 - mae: 14.3065\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 14.1740 - mae: 14.1740\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 14.0415 - mae: 14.0415\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 13.9090 - mae: 13.9090\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.7765 - mae: 13.7765\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 13.6440 - mae: 13.6440\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 13.5115 - mae: 13.5115\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 13.3790 - mae: 13.3790\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.2465 - mae: 13.2465\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 13.1140 - mae: 13.1140\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9815 - mae: 12.9815\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.8490 - mae: 12.8490\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.7165 - mae: 12.7165\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.5840 - mae: 12.5840\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.4515 - mae: 12.4515\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3190 - mae: 12.3190\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.1865 - mae: 12.1865\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 12.0540 - mae: 12.0540\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.9215 - mae: 11.9215\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.7890 - mae: 11.7890\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6565 - mae: 11.6565\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.5240 - mae: 11.5240\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.3915 - mae: 11.3915\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.2590 - mae: 11.2590\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.1265 - mae: 11.1265\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9940 - mae: 10.9940\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8615 - mae: 10.8615\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.7290 - mae: 10.7290\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5965 - mae: 10.5965\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4640 - mae: 10.4640\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.3315 - mae: 10.3315\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.1990 - mae: 10.1990\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 10.0665 - mae: 10.0665\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 9.9340 - mae: 9.9340\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.8015 - mae: 9.8015\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.6690 - mae: 9.6690\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.5365 - mae: 9.5365\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.4040 - mae: 9.4040\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.2715 - mae: 9.2715\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 9.1390 - mae: 9.1390\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.0065 - mae: 9.0065\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.8740 - mae: 8.8740\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.7415 - mae: 8.7415\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.6090 - mae: 8.6090\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.4765 - mae: 8.4765\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.3440 - mae: 8.3440\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.2115 - mae: 8.2115\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.0790 - mae: 8.0790\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.9465 - mae: 7.9465\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.8140 - mae: 7.8140\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.6815 - mae: 7.6815\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.5490 - mae: 7.5490\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.4165 - mae: 7.4165\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2840 - mae: 7.2840\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1515 - mae: 7.1515\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0190 - mae: 7.0190\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9956 - mae: 6.9956\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9900 - mae: 6.9900\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9844 - mae: 6.9844\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9788 - mae: 6.9788\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9731 - mae: 6.9731\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9675 - mae: 6.9675\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9619 - mae: 6.9619\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9563 - mae: 6.9563\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9506 - mae: 6.9506\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9450 - mae: 6.9450\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9394 - mae: 6.9394\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9338 - mae: 6.9338\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9281 - mae: 6.9281\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9225 - mae: 6.9225\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.9169 - mae: 6.9169\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9113 - mae: 6.9113\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9056 - mae: 6.9056\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9000 - mae: 6.9000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8944 - mae: 6.8944\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8888 - mae: 6.8888\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8831 - mae: 6.8831\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.8775 - mae: 6.8775\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8719 - mae: 6.8719\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8663 - mae: 6.8663\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8606 - mae: 6.8606\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8550 - mae: 6.8550\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8494 - mae: 6.8494\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8438 - mae: 6.8438\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.8381 - mae: 6.8381\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8325 - mae: 6.8325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2114a8f9520>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's rebuild our model\n",
    "\n",
    "# 1. create the model\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "#2. Compile the model\n",
    "model_1.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.SGD(),metrics=[\"mae\"])\n",
    "\n",
    "#3. Fit the model\n",
    "\n",
    "model_1.fit(tf.expand_dims(X, axis=-1), y, epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 177ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.753757]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.5217 - mae: 13.5217\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 13.4404 - mae: 13.4404\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 13.3590 - mae: 13.3590\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 13.2765 - mae: 13.2765\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 13.1918 - mae: 13.1918\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 13.1040 - mae: 13.1040\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 13.0116 - mae: 13.0116\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 12.9136 - mae: 12.9136\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 12.8088 - mae: 12.8088\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 12.6963 - mae: 12.6963\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 12.5751 - mae: 12.5751\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 12.4443 - mae: 12.4443\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 12.3031 - mae: 12.3031\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 12.1506 - mae: 12.1506\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.9858 - mae: 11.9858\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 11.8078 - mae: 11.8078\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 11.6158 - mae: 11.6158\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.4088 - mae: 11.4088\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.1859 - mae: 11.1859\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.9466 - mae: 10.9466\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.6946 - mae: 10.6946\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.4289 - mae: 10.4289\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.1507 - mae: 10.1507\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.8621 - mae: 9.8621\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 9.5747 - mae: 9.5747\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 9.2977 - mae: 9.2977\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0440 - mae: 9.0440\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.8135 - mae: 8.8135\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.6166 - mae: 8.6166\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.4634 - mae: 8.4634\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.3439 - mae: 8.3439\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.2483 - mae: 8.2483\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1640 - mae: 8.1640\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 8.0831 - mae: 8.0831\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.0039 - mae: 8.0039\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.8956 - mae: 7.8956\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.7733 - mae: 7.7733\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.6382 - mae: 7.6382\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.5047 - mae: 7.5047\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.3701 - mae: 7.3701\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2329 - mae: 7.2329\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.1283 - mae: 7.1283\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.0703 - mae: 7.0703\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0672 - mae: 7.0672\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0950 - mae: 7.0950\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1233 - mae: 7.1233\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.1383 - mae: 7.1383\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.1326 - mae: 7.1326\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1035 - mae: 7.1035\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0586 - mae: 7.0586\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0085 - mae: 7.0085\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9598 - mae: 6.9598\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.9184 - mae: 6.9184\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8862 - mae: 6.8862\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.8650 - mae: 6.8650\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.8465 - mae: 6.8465\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8279 - mae: 6.8279\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 6.8061 - mae: 6.8061\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7831 - mae: 6.7831\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.7552 - mae: 6.7552\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.7272 - mae: 6.7272\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.7005 - mae: 6.7005\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6794 - mae: 6.6794\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6643 - mae: 6.6643\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.6491 - mae: 6.6491\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.6311 - mae: 6.6311\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 6.6102 - mae: 6.6102\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.5892 - mae: 6.5892\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.5691 - mae: 6.5691\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.5484 - mae: 6.5484\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5269 - mae: 6.5269\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5050 - mae: 6.5050\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4827 - mae: 6.4827\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4605 - mae: 6.4605\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.4384 - mae: 6.4384\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4156 - mae: 6.4156\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3912 - mae: 6.3912\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3671 - mae: 6.3671\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.3448 - mae: 6.3448\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.3219 - mae: 6.3219\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.2970 - mae: 6.2970\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.2721 - mae: 6.2721\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2482 - mae: 6.2482\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 6.2229 - mae: 6.2229\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1963 - mae: 6.1963\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1697 - mae: 6.1697\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.1434 - mae: 6.1434\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.1162 - mae: 6.1162\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0873 - mae: 6.0873\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0577 - mae: 6.0577\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.0286 - mae: 6.0286\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.9994 - mae: 5.9994\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9688 - mae: 5.9688\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.9370 - mae: 5.9370\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9048 - mae: 5.9048\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8722 - mae: 5.8722\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.8393 - mae: 5.8393\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.8047 - mae: 5.8047\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.7687 - mae: 5.7687\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.7329 - mae: 5.7329\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.6957 - mae: 5.6957\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.6564 - mae: 5.6564\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.6166 - mae: 5.6166\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.5756 - mae: 5.5756\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.5328 - mae: 5.5328\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4888 - mae: 5.4888\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4442 - mae: 5.4442\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3984 - mae: 5.3984\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.3506 - mae: 5.3506\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.3013 - mae: 5.3013\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.2502 - mae: 5.2502\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.1969 - mae: 5.1969\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.1425 - mae: 5.1425\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 5.0857 - mae: 5.0857\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.0267 - mae: 5.0267\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.9656 - mae: 4.9656\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.9024 - mae: 4.9024\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.8367 - mae: 4.8367\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.7683 - mae: 4.7683\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.6981 - mae: 4.6981\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6249 - mae: 4.6249\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.5479 - mae: 4.5479\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.4677 - mae: 4.4677\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3849 - mae: 4.3849\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2980 - mae: 4.2980\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2079 - mae: 4.2079\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1139 - mae: 4.1139\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0170 - mae: 4.0170\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9154 - mae: 3.9154\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8091 - mae: 3.8091\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6988 - mae: 3.6988\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5834 - mae: 3.5834\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4622 - mae: 3.4622\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3356 - mae: 3.3356\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2041 - mae: 3.2041\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.0667 - mae: 3.0667\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.9223 - mae: 2.9223\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.7718 - mae: 2.7718\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.6140 - mae: 2.6140\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 2.4487 - mae: 2.4487\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2768 - mae: 2.2768\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0968 - mae: 2.0968\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9079 - mae: 1.9079\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.7104 - mae: 1.7104\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5042 - mae: 1.5042\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2875 - mae: 1.2875\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.0626 - mae: 1.0626\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.8259 - mae: 0.8259\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6003 - mae: 0.6003\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5213 - mae: 0.5213\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.3559 - mae: 0.3559\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3711 - mae: 0.3711\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4476 - mae: 0.4476\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5597 - mae: 0.5597\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6203 - mae: 0.6203\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6824 - mae: 0.6824\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.6865 - mae: 0.6865\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6819 - mae: 0.6819\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6221 - mae: 0.6221\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5723 - mae: 0.5723\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4812 - mae: 0.4812\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3929 - mae: 0.3929\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3132 - mae: 0.3132\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2817 - mae: 0.2817\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3021 - mae: 0.3021\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2399 - mae: 0.2399\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3439 - mae: 0.3439\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2963 - mae: 0.2963\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3481 - mae: 0.3481\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3493 - mae: 0.3493\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2908 - mae: 0.2908\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2834 - mae: 0.2834\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1898 - mae: 0.1898\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1756 - mae: 0.1756\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2051 - mae: 0.2051\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1633 - mae: 0.1633\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2413 - mae: 0.2413\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1877 - mae: 0.1877\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2791 - mae: 0.2791\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2527 - mae: 0.2527\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1897 - mae: 0.1897\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2131 - mae: 0.2131\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1011 - mae: 0.1011\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2049 - mae: 0.2049\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1042 - mae: 0.1042\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1947 - mae: 0.1947\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1383 - mae: 0.1383\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1925 - mae: 0.1925\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1659 - mae: 0.1659\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1305 - mae: 0.1305\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1530 - mae: 0.1530\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1156 - mae: 0.1156\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1102 - mae: 0.1102\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1362 - mae: 0.1362\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0939 - mae: 0.0939\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1482 - mae: 0.1482\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1127 - mae: 0.1127\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1471 - mae: 0.1471\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1160 - mae: 0.1160\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1505 - mae: 0.1505\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1478 - mae: 0.1478\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1159 - mae: 0.1159\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1395 - mae: 0.1395\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0902 - mae: 0.0902\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0961 - mae: 0.0961\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1016 - mae: 0.1016\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0846 - mae: 0.0846\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1113 - mae: 0.1113\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0733 - mae: 0.0733\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0970 - mae: 0.0970\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0611 - mae: 0.0611\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0658 - mae: 0.0658\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0777 - mae: 0.0777\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0622 - mae: 0.0622\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0530 - mae: 0.0530\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0711 - mae: 0.0711\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0672 - mae: 0.0672\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0624 - mae: 0.0624\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0649 - mae: 0.0649\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0649 - mae: 0.0649\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0540 - mae: 0.0540\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0510 - mae: 0.0510\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0539 - mae: 0.0539\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0714 - mae: 0.0714\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0605 - mae: 0.0605\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0515 - mae: 0.0515\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0533 - mae: 0.0533\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0605 - mae: 0.0605\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0651 - mae: 0.0651\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0551 - mae: 0.0551\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0564 - mae: 0.0564\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0646 - mae: 0.0646\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0682 - mae: 0.0682\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0584 - mae: 0.0584\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0618 - mae: 0.0618\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.0542 - mae: 0.0542\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0504 - mae: 0.0504\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0521 - mae: 0.0521\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0489 - mae: 0.0489\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0435 - mae: 0.0435\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0413 - mae: 0.0413\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0493 - mae: 0.0493\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0465 - mae: 0.0465\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0499 - mae: 0.0499\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0534 - mae: 0.0534\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0553 - mae: 0.0553\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0468 - mae: 0.0468\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0430 - mae: 0.0430\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0498 - mae: 0.0498\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0581 - mae: 0.0581\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0577 - mae: 0.0577\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0532 - mae: 0.0532\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0465 - mae: 0.0465\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0404 - mae: 0.0404\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0437 - mae: 0.0437\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0562 - mae: 0.0562\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0543 - mae: 0.0543\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0447 - mae: 0.0447\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0457 - mae: 0.0457\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0610 - mae: 0.0610\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0644 - mae: 0.0644\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0435 - mae: 0.0435\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0382 - mae: 0.0382\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0852 - mae: 0.0852\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0522 - mae: 0.0522\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0485 - mae: 0.0485\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0913 - mae: 0.0913\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0497 - mae: 0.0497\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0794 - mae: 0.0794\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0636 - mae: 0.0636\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0434 - mae: 0.0434\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0494 - mae: 0.0494\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0734 - mae: 0.0734\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0583 - mae: 0.0583\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0425 - mae: 0.0425\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0513 - mae: 0.0513\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0626 - mae: 0.0626\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0540 - mae: 0.0540\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0487 - mae: 0.0487\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0692 - mae: 0.0692\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0567 - mae: 0.0567\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0442 - mae: 0.0442\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0711 - mae: 0.0711\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0585 - mae: 0.0585\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0478 - mae: 0.0478\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0694 - mae: 0.0694\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0642 - mae: 0.0642\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0501 - mae: 0.0501\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0617 - mae: 0.0617\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0454 - mae: 0.0454\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0410 - mae: 0.0410\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0415 - mae: 0.0415\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0405 - mae: 0.0405\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0420 - mae: 0.0420\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0572 - mae: 0.0572\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0581 - mae: 0.0581\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0513 - mae: 0.0513\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0438 - mae: 0.0438\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0510 - mae: 0.0510\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0683 - mae: 0.0683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2114bb36be0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the new model\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(100),\n",
    "    tf.keras.layers.Dense(100),\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "model_2.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(lr=0.0011), metrics=[\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "model_2.fit(tf.expand_dims(X, axis=-1), y, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=27.06004>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=28.063671>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model_2.predict([17.0, 18.0])\n",
    "y_preds_avg_0 = tf.reduce_mean(y_preds[0])\n",
    "y_preds_avg_1 = tf.reduce_mean(y_preds[1])\n",
    "y_preds_avg_0, y_preds_avg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.5831 - mae: 13.5831\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.2125 - mae: 13.2125\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.8480 - mae: 12.8480\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.5000 - mae: 12.5000\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.1774 - mae: 12.1774\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.8678 - mae: 11.8678\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.5521 - mae: 11.5521\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2175 - mae: 11.2175\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.8745 - mae: 10.8745\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5787 - mae: 10.5787\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.2863 - mae: 10.2863\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 9.9771 - mae: 9.9771\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.6516 - mae: 9.6516\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.3034 - mae: 9.3034\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9300 - mae: 8.9300\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5339 - mae: 8.5339\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.1254 - mae: 8.1254\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.6879 - mae: 7.6879\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.2239 - mae: 7.2239\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.7309 - mae: 6.7309\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.2031 - mae: 6.2031\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.6378 - mae: 5.6378\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.0296 - mae: 5.0296\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 4.3796 - mae: 4.3796\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 4.0402 - mae: 4.0402\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9665 - mae: 3.9665\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.1084 - mae: 4.1084\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.2326 - mae: 4.2326\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.4644 - mae: 4.4644\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.6652 - mae: 4.6652\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.7771 - mae: 4.7771\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.8088 - mae: 4.8088\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.7708 - mae: 4.7708\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.6748 - mae: 4.6748\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.5294 - mae: 4.5294\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3449 - mae: 4.3449\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.1620 - mae: 4.1620\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0759 - mae: 4.0759\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9906 - mae: 3.9906\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9106 - mae: 3.9106\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 3.8320 - mae: 3.8320\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7720 - mae: 3.7720\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8318 - mae: 3.8318\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8711 - mae: 3.8711\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8943 - mae: 3.8943\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.9026 - mae: 3.9026\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8969 - mae: 3.8969\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8792 - mae: 3.8792\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8507 - mae: 3.8507\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.8119 - mae: 3.8119\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7669 - mae: 3.7669\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7121 - mae: 3.7121\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.6665 - mae: 3.6665\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.6887 - mae: 3.6887\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7006 - mae: 3.7006\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.7022 - mae: 3.7022\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6946 - mae: 3.6946\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6792 - mae: 3.6792\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6754 - mae: 3.6754\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6331 - mae: 3.6331\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6031 - mae: 3.6031\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5887 - mae: 3.5887\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5994 - mae: 3.5994\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 3.5932 - mae: 3.5932\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.5693 - mae: 3.5693\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5342 - mae: 3.5342\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5334 - mae: 3.5334\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5243 - mae: 3.5243\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5083 - mae: 3.5083\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.5049 - mae: 3.5049\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4952 - mae: 3.4952\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4716 - mae: 3.4716\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.4610 - mae: 3.4610\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4453 - mae: 3.4453\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4308 - mae: 3.4308\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4158 - mae: 3.4158\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4099 - mae: 3.4099\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3828 - mae: 3.3828\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.3704 - mae: 3.3704\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3547 - mae: 3.3547\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3459 - mae: 3.3459\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3236 - mae: 3.3236\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.3107 - mae: 3.3107\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2902 - mae: 3.2902\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2680 - mae: 3.2680\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2556 - mae: 3.2556\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2376 - mae: 3.2376\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.2109 - mae: 3.2109\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1892 - mae: 3.1892\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1854 - mae: 3.1854\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1748 - mae: 3.1748\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.1521 - mae: 3.1521\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1163 - mae: 3.1163\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0977 - mae: 3.0977\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.0727 - mae: 3.0727\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0332 - mae: 3.0332\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 3.0091 - mae: 3.0091\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.9804 - mae: 2.9804\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 2.9718 - mae: 2.9718\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.9417 - mae: 2.9417\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9096 - mae: 2.9096\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8918 - mae: 2.8918\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8575 - mae: 2.8575\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.8103 - mae: 2.8103\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.8062 - mae: 2.8062\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.7687 - mae: 2.7687\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6953 - mae: 2.6953\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6892 - mae: 2.6892\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.6698 - mae: 2.6698\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.6662 - mae: 2.6662\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5919 - mae: 2.5919\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.5341 - mae: 2.5341\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4678 - mae: 2.4678\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4469 - mae: 2.4469\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.4096 - mae: 2.4096\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.3135 - mae: 2.3135\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.2718 - mae: 2.2718\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.2369 - mae: 2.2369\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.1784 - mae: 2.1784\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.1003 - mae: 2.1003\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 2.0340 - mae: 2.0340\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.9547 - mae: 1.9547\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.8604 - mae: 1.8604\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.8358 - mae: 1.8358\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7551 - mae: 1.7551\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6333 - mae: 1.6333\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5675 - mae: 1.5675\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4805 - mae: 1.4805\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.3743 - mae: 1.3743\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2449 - mae: 1.2449\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1969 - mae: 1.1969\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.0719 - mae: 1.0719\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.9005 - mae: 0.9005\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.8379 - mae: 0.8379\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.7844 - mae: 0.7844\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6946 - mae: 0.6946\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7697 - mae: 0.7697\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7028 - mae: 0.7028\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6686 - mae: 0.6686\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6945 - mae: 0.6945\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5897 - mae: 0.5897\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6007 - mae: 0.6007\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6779 - mae: 0.6779\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6793 - mae: 0.6793\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6747 - mae: 0.6747\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4494 - mae: 0.4494\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6716 - mae: 0.6716\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5866 - mae: 0.5866\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6612 - mae: 0.6612\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5946 - mae: 0.5946\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3650 - mae: 0.3650\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.5522 - mae: 0.5522\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3805 - mae: 0.3805\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3907 - mae: 0.3907\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.2895 - mae: 0.2895\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4722 - mae: 0.4722\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3116 - mae: 0.3116\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2446 - mae: 0.2446\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5389 - mae: 0.5389\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4695 - mae: 0.4695\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.4627 - mae: 0.4627\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4816 - mae: 0.4816\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2366 - mae: 0.2366\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4294 - mae: 0.4294\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2727 - mae: 0.2727\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5367 - mae: 0.5367\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6075 - mae: 0.6075\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.4313 - mae: 0.4313\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3952 - mae: 0.3952\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5315 - mae: 0.5315\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3400 - mae: 0.3400\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2661 - mae: 0.2661\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3233 - mae: 0.3233\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2118 - mae: 0.2118\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3424 - mae: 0.3424\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3509 - mae: 0.3509\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2071 - mae: 0.2071\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3545 - mae: 0.3545\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3698 - mae: 0.3698\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1972 - mae: 0.1972\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2456 - mae: 0.2456\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2224 - mae: 0.2224\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1370 - mae: 0.1370\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1971 - mae: 0.1971\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1279 - mae: 0.1279\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1231 - mae: 0.1231\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1410 - mae: 0.1410\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0642 - mae: 0.0642\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2698 - mae: 0.2698\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2881 - mae: 0.2881\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0559 - mae: 0.0559\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4169 - mae: 0.4169\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5410 - mae: 0.5410\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4076 - mae: 0.4076\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0642 - mae: 0.0642\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5305 - mae: 0.5305\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.7941 - mae: 0.7941\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7588 - mae: 0.7588\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.4600 - mae: 0.4600\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0632 - mae: 0.0632\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2730 - mae: 0.2730\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2187 - mae: 0.2187\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0908 - mae: 0.0908\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1105 - mae: 0.1105\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1196 - mae: 0.1196\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0774 - mae: 0.0774\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1982 - mae: 0.1982\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1966 - mae: 0.1966\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1100 - mae: 0.1100\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0794 - mae: 0.0794\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0763 - mae: 0.0763\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1145 - mae: 0.1145\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1276 - mae: 0.1276\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1054 - mae: 0.1054\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1848 - mae: 0.1848\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1589 - mae: 0.1589\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1138 - mae: 0.1138\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1346 - mae: 0.1346\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1776 - mae: 0.1776\n",
      "Epoch 220/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1312 - mae: 0.1312\n",
      "Epoch 221/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1603 - mae: 0.1603\n",
      "Epoch 222/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2241 - mae: 0.2241\n",
      "Epoch 223/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1435 - mae: 0.1435\n",
      "Epoch 224/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2611 - mae: 0.2611\n",
      "Epoch 225/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1682 - mae: 0.1682\n",
      "Epoch 226/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1284 - mae: 0.1284\n",
      "Epoch 227/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1795 - mae: 0.1795\n",
      "Epoch 228/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1347 - mae: 0.1347\n",
      "Epoch 229/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0749 - mae: 0.0749\n",
      "Epoch 230/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0615 - mae: 0.0615\n",
      "Epoch 231/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1175 - mae: 0.1175\n",
      "Epoch 232/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0486 - mae: 0.0486\n",
      "Epoch 233/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2173 - mae: 0.2173\n",
      "Epoch 234/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2529 - mae: 0.2529\n",
      "Epoch 235/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0848 - mae: 0.0848\n",
      "Epoch 236/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2569 - mae: 0.2569\n",
      "Epoch 237/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3474 - mae: 0.3474\n",
      "Epoch 238/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2221 - mae: 0.2221\n",
      "Epoch 239/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0859 - mae: 0.0859\n",
      "Epoch 240/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1600 - mae: 0.1600\n",
      "Epoch 241/300\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0576 - mae: 0.0576\n",
      "Epoch 242/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1769 - mae: 0.1769\n",
      "Epoch 243/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1799 - mae: 0.1799\n",
      "Epoch 244/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0499 - mae: 0.0499\n",
      "Epoch 245/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1329 - mae: 0.1329\n",
      "Epoch 246/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0512 - mae: 0.0512\n",
      "Epoch 247/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2495 - mae: 0.2495\n",
      "Epoch 248/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2669 - mae: 0.2669\n",
      "Epoch 249/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0912 - mae: 0.0912\n",
      "Epoch 250/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2959 - mae: 0.2959\n",
      "Epoch 251/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4003 - mae: 0.4003\n",
      "Epoch 252/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3469 - mae: 0.3469\n",
      "Epoch 253/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1182 - mae: 0.1182\n",
      "Epoch 254/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3857 - mae: 0.3857\n",
      "Epoch 255/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5216 - mae: 0.5216\n",
      "Epoch 256/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4972 - mae: 0.4972\n",
      "Epoch 257/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2752 - mae: 0.2752\n",
      "Epoch 258/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1417 - mae: 0.1417\n",
      "Epoch 259/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2890 - mae: 0.2890\n",
      "Epoch 260/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2491 - mae: 0.2491\n",
      "Epoch 261/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0435 - mae: 0.0435\n",
      "Epoch 262/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2691 - mae: 0.2691\n",
      "Epoch 263/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3348 - mae: 0.3348\n",
      "Epoch 264/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1975 - mae: 0.1975\n",
      "Epoch 265/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1232 - mae: 0.1232\n",
      "Epoch 266/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2151 - mae: 0.2151\n",
      "Epoch 267/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1198 - mae: 0.1198\n",
      "Epoch 268/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1542 - mae: 0.1542\n",
      "Epoch 269/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2026 - mae: 0.2026\n",
      "Epoch 270/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0703 - mae: 0.0703\n",
      "Epoch 271/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2357 - mae: 0.2357\n",
      "Epoch 272/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3238 - mae: 0.3238\n",
      "Epoch 273/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2342 - mae: 0.2342\n",
      "Epoch 274/300\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0378 - mae: 0.0378\n",
      "Epoch 275/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1011 - mae: 0.1011\n",
      "Epoch 276/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0325 - mae: 0.0325\n",
      "Epoch 277/300\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0794 - mae: 0.0794\n",
      "Epoch 278/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0737 - mae: 0.0737\n",
      "Epoch 279/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0258 - mae: 0.0258\n",
      "Epoch 280/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0716 - mae: 0.0716\n",
      "Epoch 281/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0659 - mae: 0.0659\n",
      "Epoch 282/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0394 - mae: 0.0394\n",
      "Epoch 283/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0950 - mae: 0.0950\n",
      "Epoch 284/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0363 - mae: 0.0363\n",
      "Epoch 285/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0721 - mae: 0.0721\n",
      "Epoch 286/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0641 - mae: 0.0641\n",
      "Epoch 287/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0209 - mae: 0.0209\n",
      "Epoch 288/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0144 - mae: 0.0144\n",
      "Epoch 289/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1671 - mae: 0.1671\n",
      "Epoch 290/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1428 - mae: 0.1428\n",
      "Epoch 291/300\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0736 - mae: 0.0736\n",
      "Epoch 292/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0955 - mae: 0.0955\n",
      "Epoch 293/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0852 - mae: 0.0852\n",
      "Epoch 294/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0761 - mae: 0.0761\n",
      "Epoch 295/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1608 - mae: 0.1608\n",
      "Epoch 296/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1712 - mae: 0.1712\n",
      "Epoch 297/300\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0354 - mae: 0.0354\n",
      "Epoch 298/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0320 - mae: 0.0320\n",
      "Epoch 299/300\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1300 - mae: 0.1300\n",
      "Epoch 300/300\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0972 - mae: 0.0972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2114cc65e50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. create a model again\n",
    "model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "# compile the model\n",
    "model_3.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=[\"mae\"])\n",
    "\n",
    "# Fix the model\n",
    "model_3.fit(tf.expand_dims(X, axis=-1), y, epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## increasing the size of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26.,\n",
       "        27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39.,\n",
       "        40., 41., 42., 43., 44., 45., 46., 47., 48., 49.]),\n",
       " array([11., 12., 13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23.,\n",
       "        24., 25., 26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36.,\n",
       "        37., 38., 39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49.,\n",
       "        50., 51., 52., 53., 54., 55., 56., 57., 58., 59.]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array([])\n",
    "y_train = np.array([])\n",
    "for i in range(1, 50):\n",
    "    X_train = np.append(X_train, i)\n",
    "    y_train = np.append(y_train, i+10)\n",
    "X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/167\n",
      "1/1 [==============================] - 2s 2s/step - loss: 13.4943 - mae: 13.4943\n",
      "Epoch 2/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 12.6801 - mae: 12.6801\n",
      "Epoch 3/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 11.9667 - mae: 11.9667\n",
      "Epoch 4/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 11.3147 - mae: 11.3147\n",
      "Epoch 5/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.6351 - mae: 10.6351\n",
      "Epoch 6/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 10.0705 - mae: 10.0705\n",
      "Epoch 7/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 9.4816 - mae: 9.4816\n",
      "Epoch 8/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.8376 - mae: 8.8376\n",
      "Epoch 9/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1165 - mae: 8.1165\n",
      "Epoch 10/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3212 - mae: 7.3212\n",
      "Epoch 11/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4343 - mae: 6.4343\n",
      "Epoch 12/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.4444 - mae: 5.4444\n",
      "Epoch 13/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3373 - mae: 4.3373\n",
      "Epoch 14/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.0541 - mae: 4.0541\n",
      "Epoch 15/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.3164 - mae: 4.3164\n",
      "Epoch 16/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.8209 - mae: 4.8209\n",
      "Epoch 17/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.2167 - mae: 5.2167\n",
      "Epoch 18/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.4117 - mae: 5.4117\n",
      "Epoch 19/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.4324 - mae: 5.4324\n",
      "Epoch 20/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 5.3081 - mae: 5.3081\n",
      "Epoch 21/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 5.0739 - mae: 5.0739\n",
      "Epoch 22/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.7543 - mae: 4.7543\n",
      "Epoch 23/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.3685 - mae: 4.3685\n",
      "Epoch 24/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 4.1275 - mae: 4.1275\n",
      "Epoch 25/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9652 - mae: 3.9652\n",
      "Epoch 26/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8451 - mae: 3.8451\n",
      "Epoch 27/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9657 - mae: 3.9657\n",
      "Epoch 28/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 4.0512 - mae: 4.0512\n",
      "Epoch 29/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2131 - mae: 4.2131\n",
      "Epoch 30/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.2309 - mae: 4.2309\n",
      "Epoch 31/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.0791 - mae: 4.0791\n",
      "Epoch 32/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9580 - mae: 3.9580\n",
      "Epoch 33/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8345 - mae: 3.8345\n",
      "Epoch 34/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7069 - mae: 3.7069\n",
      "Epoch 35/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7667 - mae: 3.7667\n",
      "Epoch 36/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8100 - mae: 3.8100\n",
      "Epoch 37/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8364 - mae: 3.8364\n",
      "Epoch 38/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8480 - mae: 3.8480\n",
      "Epoch 39/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.8441 - mae: 3.8441\n",
      "Epoch 40/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8264 - mae: 3.8264\n",
      "Epoch 41/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7966 - mae: 3.7966\n",
      "Epoch 42/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.7554 - mae: 3.7554\n",
      "Epoch 43/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.7046 - mae: 3.7046\n",
      "Epoch 44/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.6455 - mae: 3.6455\n",
      "Epoch 45/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5791 - mae: 3.5791\n",
      "Epoch 46/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6002 - mae: 3.6002\n",
      "Epoch 47/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.6305 - mae: 3.6305\n",
      "Epoch 48/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.6222 - mae: 3.6222\n",
      "Epoch 49/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.5921 - mae: 3.5921\n",
      "Epoch 50/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.5346 - mae: 3.5346\n",
      "Epoch 51/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4561 - mae: 3.4561\n",
      "Epoch 52/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.4601 - mae: 3.4601\n",
      "Epoch 53/167\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.4475 - mae: 3.4475\n",
      "Epoch 54/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.4208 - mae: 3.4208\n",
      "Epoch 55/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3787 - mae: 3.3787\n",
      "Epoch 56/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.3390 - mae: 3.3390\n",
      "Epoch 57/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.3334 - mae: 3.3334\n",
      "Epoch 58/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2909 - mae: 3.2909\n",
      "Epoch 59/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2770 - mae: 3.2770\n",
      "Epoch 60/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2436 - mae: 3.2436\n",
      "Epoch 61/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.1896 - mae: 3.1896\n",
      "Epoch 62/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.2061 - mae: 3.2061\n",
      "Epoch 63/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.1683 - mae: 3.1683\n",
      "Epoch 64/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0836 - mae: 3.0836\n",
      "Epoch 65/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0721 - mae: 3.0721\n",
      "Epoch 66/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 3.0541 - mae: 3.0541\n",
      "Epoch 67/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.0118 - mae: 3.0118\n",
      "Epoch 68/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.9478 - mae: 2.9478\n",
      "Epoch 69/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.8804 - mae: 2.8804\n",
      "Epoch 70/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7822 - mae: 2.7822\n",
      "Epoch 71/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.7063 - mae: 2.7063\n",
      "Epoch 72/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.6428 - mae: 2.6428\n",
      "Epoch 73/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.5762 - mae: 2.5762\n",
      "Epoch 74/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.5149 - mae: 2.5149\n",
      "Epoch 75/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.4301 - mae: 2.4301\n",
      "Epoch 76/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.3200 - mae: 2.3200\n",
      "Epoch 77/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.2495 - mae: 2.2495\n",
      "Epoch 78/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.1212 - mae: 2.1212\n",
      "Epoch 79/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.0292 - mae: 2.0292\n",
      "Epoch 80/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.9366 - mae: 1.9366\n",
      "Epoch 81/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.8109 - mae: 1.8109\n",
      "Epoch 82/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.6481 - mae: 1.6481\n",
      "Epoch 83/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.4467 - mae: 1.4467\n",
      "Epoch 84/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2905 - mae: 1.2905\n",
      "Epoch 85/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.0788 - mae: 1.0788\n",
      "Epoch 86/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.9562 - mae: 0.9562\n",
      "Epoch 87/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.0187 - mae: 1.0187\n",
      "Epoch 88/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7495 - mae: 0.7495\n",
      "Epoch 89/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.5301 - mae: 0.5301\n",
      "Epoch 90/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4973 - mae: 0.4973\n",
      "Epoch 91/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5425 - mae: 0.5425\n",
      "Epoch 92/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6119 - mae: 0.6119\n",
      "Epoch 93/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5718 - mae: 0.5718\n",
      "Epoch 94/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3581 - mae: 0.3581\n",
      "Epoch 95/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6671 - mae: 0.6671\n",
      "Epoch 96/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6241 - mae: 0.6241\n",
      "Epoch 97/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7344 - mae: 0.7344\n",
      "Epoch 98/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5745 - mae: 0.5745\n",
      "Epoch 99/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7231 - mae: 0.7231\n",
      "Epoch 100/167\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9138 - mae: 0.9138\n",
      "Epoch 101/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6079 - mae: 0.6079\n",
      "Epoch 102/167\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6969 - mae: 0.6969\n",
      "Epoch 103/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7095 - mae: 0.7095\n",
      "Epoch 104/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3860 - mae: 0.3860\n",
      "Epoch 105/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5596 - mae: 0.5596\n",
      "Epoch 106/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4932 - mae: 0.4932\n",
      "Epoch 107/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3775 - mae: 0.3775\n",
      "Epoch 108/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6467 - mae: 0.6467\n",
      "Epoch 109/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4879 - mae: 0.4879\n",
      "Epoch 110/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3217 - mae: 0.3217\n",
      "Epoch 111/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5305 - mae: 0.5305\n",
      "Epoch 112/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4228 - mae: 0.4228\n",
      "Epoch 113/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2381 - mae: 0.2381\n",
      "Epoch 114/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4534 - mae: 0.4534\n",
      "Epoch 115/167\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4185 - mae: 0.4185\n",
      "Epoch 116/167\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2133 - mae: 0.2133\n",
      "Epoch 117/167\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4181 - mae: 0.4181\n",
      "Epoch 118/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3547 - mae: 0.3547\n",
      "Epoch 119/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1881 - mae: 0.1881\n",
      "Epoch 120/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4123 - mae: 0.4123\n",
      "Epoch 121/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1808 - mae: 0.1808\n",
      "Epoch 122/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3327 - mae: 0.3327\n",
      "Epoch 123/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3445 - mae: 0.3445\n",
      "Epoch 124/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1229 - mae: 0.1229\n",
      "Epoch 125/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4164 - mae: 0.4164\n",
      "Epoch 126/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3710 - mae: 0.3710\n",
      "Epoch 127/167\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1410 - mae: 0.1410\n",
      "Epoch 128/167\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1629 - mae: 0.1629\n",
      "Epoch 129/167\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2573 - mae: 0.2573\n",
      "Epoch 130/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2139 - mae: 0.2139\n",
      "Epoch 131/167\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2547 - mae: 0.2547\n",
      "Epoch 132/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2727 - mae: 0.2727\n",
      "Epoch 133/167\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2528 - mae: 0.2528\n",
      "Epoch 134/167\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1576 - mae: 0.1576\n",
      "Epoch 135/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3630 - mae: 0.3630\n",
      "Epoch 136/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4011 - mae: 0.4011\n",
      "Epoch 137/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1199 - mae: 0.1199\n",
      "Epoch 138/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2180 - mae: 0.2180\n",
      "Epoch 139/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1482 - mae: 0.1482\n",
      "Epoch 140/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0866 - mae: 0.0866\n",
      "Epoch 141/167\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1495 - mae: 0.1495\n",
      "Epoch 142/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1870 - mae: 0.1870\n",
      "Epoch 143/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0590 - mae: 0.0590\n",
      "Epoch 144/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2865 - mae: 0.2865\n",
      "Epoch 145/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0809 - mae: 0.0809\n",
      "Epoch 146/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5126 - mae: 0.5126\n",
      "Epoch 147/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6439 - mae: 0.6439\n",
      "Epoch 148/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3784 - mae: 0.3784\n",
      "Epoch 149/167\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2605 - mae: 0.2605\n",
      "Epoch 150/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4204 - mae: 0.4204\n",
      "Epoch 151/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1473 - mae: 0.1473\n",
      "Epoch 152/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4754 - mae: 0.4754\n",
      "Epoch 153/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6538 - mae: 0.6538\n",
      "Epoch 154/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4497 - mae: 0.4497\n",
      "Epoch 155/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1213 - mae: 0.1213\n",
      "Epoch 156/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4489 - mae: 0.4489\n",
      "Epoch 157/167\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3718 - mae: 0.3718\n",
      "Epoch 158/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1180 - mae: 0.1180\n",
      "Epoch 159/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2755 - mae: 0.2755\n",
      "Epoch 160/167\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1035 - mae: 0.1035\n",
      "Epoch 161/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2720 - mae: 0.2720\n",
      "Epoch 162/167\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2235 - mae: 0.2235\n",
      "Epoch 163/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2986 - mae: 0.2986\n",
      "Epoch 164/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3035 - mae: 0.3035\n",
      "Epoch 165/167\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0952 - mae: 0.0952\n",
      "Epoch 166/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3952 - mae: 0.3952\n",
      "Epoch 167/167\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.3413 - mae: 0.3413\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2114dda5370>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. make the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(200, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 2. compile the model\n",
    "model.compile(loss=tf.keras.losses.mae, optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),metrics=[\"mae\"])\n",
    "\n",
    "# 3. fit the model\n",
    "model.fit(tf.expand_dims(X, axis=-1), y, epochs=167)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "In practice, a typical workfolw you'll go through when building neural network it's\n",
    "\n",
    "```\n",
    "> Build a model -> fit it -> evaulate it -> tweak a model -> fit it -> evaluate it -> tweak a model...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when it comes to evaulation ... there are 3 words you should memorize :\n",
    "\n",
    "> \"Visualize, Visualize, visualize\"\n",
    "\n",
    "It's a good idea to visualize\n",
    "* The data - what data are working with? What does it look like?\n",
    "* the model itself -what does our model look like?\n",
    "* The training of a model - how does a model perform when it learns?\n",
    "* The predictions of the model - how do the predictions of a model line up against the ground truth (the original lables)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a bigger dataset\n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = X+10\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2114cc6aa00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The 3 sets...\n",
    "* **Training set**- the model learns from this data, which is typically 70-80% of the total data you have available \n",
    "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available\n",
    "* **Test set** - the model gets evaluated on this data to test what has learned this set is typically 10-15% of the data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the length of how many samples we have\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data and train and test sets\n",
    "X_train = X[:40]\n",
    "y_train = X[:40]\n",
    "\n",
    "X_test = X[40:]\n",
    "y_test = X[40:]\n",
    "\n",
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualising the data\n",
    "Now we'have got our data in training and test ... let's visualize it again !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=10,7)\n",
    "# # plto training data in blue\n",
    "# # plot test data in green\n",
    "# pl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4aacd395d5d951c2466a2e4b54704378f4880435fcfdaf771d34a37f91fe975"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
